#!/bin/bash

cat <<'BANNER'

# ------------------------------------------------------------------------------
# CUT&RUN PIPELINE WITH E. COLI SPIKE‚ÄëIN SCALING (PE SEQUENCING ONLY)
# ------------------------------------------------------------------------------
# This script processes CUT&RUN paired‚Äëend FASTQs through trimming, alignment,
# duplicate removal, fragment filtering, peak calling, BigWig generation,
# gene‚Äëfeature annotation, and reporting. This version includes alignment of
# trimmed reads to the standard E.¬†coli genome for normalization and scaling.
# ------------------------------------------------------------------------------

################################################################################
#              STEPS                                                           #
################################################################################
#  ---- Preparatory steps                                                      # 
# 0  Load parameters from config.json                                          #
# 1  Paths to tools and software                                               #
# 2  Create required directories                                               #
# 3  Utility functions                                                         #
# 4  Derive filenames for downstream steps                                     #
# 5  Get numeric genome size (currently supporting hs, dm, mm, sc, and ce      #
#  ---- Computational steps                                                    #
# 6  FASTQC (raw reads)                                                        #
# 7  Adapter trimming (Trim Galore!)  ‚Äì  trim ALL declared FASTQ pairs         #
# 8  Include/exclude control sample logic (for downstream steps)               #
# 9  Spike-in alignment (E. coli) with STAR                                    #
# 10  Host‚Äëgenome alignment with STAR                                          #
# 11  Picard: Add RG + MarkDuplicates                                          #
# 12  Fragment‚Äëlength filtering                                                #   
# 13  Peak calling (MACS2)                                                     #
# 14  Calculate spike-in scaling factors                                       #
# 15  BigWig generation (with scaling)                                         #
# 16¬† Peak annotation                                                          #
################################################################################

BANNER

set -o pipefail

# ------------------------------------------------------------------------------
# 0¬†¬†Load parameters from config.json
# ------------------------------------------------------------------------------
CONFIG_FILE="/mnt/data/home/aviv/cut_and_run/config.json"

RAW_FASTQ_DIR=$(jq -r '.raw_fastq_dir'              "$CONFIG_FILE")
ALIGNMENT_DIR=$(jq -r '.alignment_dir'              "$CONFIG_FILE")
OUTPUT_DIR=$(jq  -r '.output_dir'                   "$CONFIG_FILE")
LOG_DIR=$(jq     -r '.log_dir'                      "$CONFIG_FILE")

TREATMENT_R1=$(jq -r '.samples.treatment.r1'        "$CONFIG_FILE")
TREATMENT_R2=$(jq -r '.samples.treatment.r2'        "$CONFIG_FILE")
CONTROL_R1=$(  jq -r '.samples.control.r1 // empty' "$CONFIG_FILE")
CONTROL_R2=$(  jq -r '.samples.control.r2 // empty' "$CONFIG_FILE")

REFERENCE_GENOME=$(jq -r '.reference_genome'        "$CONFIG_FILE")
ANNOTATION_GENES=$(jq -r '.annotation_genes'        "$CONFIG_FILE")
CHROM_SIZE=$(      jq -r '.chrom_sizes'             "$CONFIG_FILE")
ECOLI_INDEX=$(     jq -r '.ecoli_index'             "$CONFIG_FILE")

# Dbug paths
echo "DEBUG paths: T1=$TREATMENT_R1  T2=$TREATMENT_R2  C1=$CONTROL_R1  C2=$CONTROL_R2"

# Optional explicit spike‚Äëin BAM directory; default ‚Üí <alignment>/spikein
SPIKE_BAM_DIR=$(jq -r '.spike_bam_dir // empty'     "$CONFIG_FILE")
[ -z "$SPIKE_BAM_DIR" ] || [ "$SPIKE_BAM_DIR" = "null" ] && \
  SPIKE_BAM_DIR="$ALIGNMENT_DIR/spikein"

GENOME_SIZE_STRING=$(jq -r '.genome_size'            "$CONFIG_FILE")
FRAGMENT_SIZE_FILTER=$(jq -r '.fragment_size_filter' "$CONFIG_FILE")
CUSTOM_GENOME_SIZE=$( jq -r '.custom_genome_size'    "$CONFIG_FILE")
NUM_THREADS=$(       jq -r '.num_threads'            "$CONFIG_FILE")

# When read count is low or fragment length is narrow (as expected in histone or TF targeting experiments), MACS2 simply falls back to non-model-based peak calling and recommends these extsizes. Used in SE only.
BROAD_EXTSIZE=$( jq -r '.broad_peak_extsize'  "$CONFIG_FILE")
NARROW_EXTSIZE=$(jq -r '.narrow_peak_extsize' "$CONFIG_FILE")

# ------------------------------------------------------------------------------
# Build FASTQ_FILES array 
# ------------------------------------------------------------------------------
FASTQ_FILES=("$TREATMENT_R1" "$TREATMENT_R2")

# Only push control files if they exist
if [[ -n "$CONTROL_R1" && -n "$CONTROL_R2" ]]; then
  FASTQ_FILES+=("$CONTROL_R1" "$CONTROL_R2")
fi

# ------------------------------------------------------------------------------
# 1 Paths to tools and software
# ------------------------------------------------------------------------------
# Picard tools path
PICARD_PATH="/mnt/data/home/aviv/tools/picard.jar"  # Path to the Picard jar file (e.g., picard.jar)
# FastQC tools path
FASTQC_PATH="/mnt/data/home/aviv/tools/FastQC/fastqc"
# STAR path
STAR_PATH="/mnt/data/home/aviv/tools/STAR/STAR-2.7.11b/bin/Linux_x86_64/STAR"
# SEACR path
SEACR=/mnt/data/home/aviv/tools/SEACR/SEACR_1.3.sh

# -----------------------------------------------------------------------------
# 2¬†¬†Create required directories
# -----------------------------------------------------------------------------
mkdir -p "$OUTPUT_DIR" "$LOG_DIR" "$ALIGNMENT_DIR" "$SPIKE_BAM_DIR"
FASTQC_DIR="$OUTPUT_DIR/fastqc_reports";    mkdir -p "$FASTQC_DIR"
PEAK_DIR="$OUTPUT_DIR/macs2_peaks";         mkdir -p "$PEAK_DIR"
BW_DIR="$OUTPUT_DIR/bigwig_bedgraphs";      mkdir -p "$BW_DIR"
ANN_DIR="$OUTPUT_DIR/annotated_peaks";      mkdir -p "$ANN_DIR"
MULTIQC_DIR="$OUTPUT_DIR/multiqc_reports";  mkdir -p "$MULTIQC_DIR"

# ------------------------------------------------------------------------------
# 3¬†¬†Utility functions
# ------------------------------------------------------------------------------
get_sample_basename() {
  local f=$1
  local b=${f##*/}            # strip directory
  b=${b%.fastq.gz}; b=${b%.fq.gz}
  b=${b%_R1_001};  b=${b%_R2_001}   # ‚Üê strip the full _R#_001 suffix
  b=${b%_R1};      b=${b%_R2}       # fallback for plain _R1/_R2
  b=${b%_1};       b=${b%_2}        # fallback for _1/_2
  echo "$b" | sed 's/[^A-Za-z0-9._-]//g'
}

# Usage: run_star <STAR_index> <R1> <R2> <outPrefix> <logBase>
# Runs STAR ‚Üí sorted BAM + logs.
run_star() {
  local index=$1 r1=$2 r2=$3 prefix=$4 logbase=$5
  "$STAR_PATH" --runThreadN "$NUM_THREADS" \
               --genomeDir  "$REFERENCE_GENOME" \
               --readFilesIn "$r1" "$r2" \
               --readFilesCommand zcat \
               --outSAMtype BAM SortedByCoordinate \
               --outFileNamePrefix "$prefix" \
               > "$LOG_DIR/${logbase}.log"  \
               2> "$LOG_DIR/${logbase}_err.log"
}

run_spikein_align() {
  # Align trimmed reads to E.¬†coli spike‚Äëin genome with STAR.
  # Usage: run_spikein_align R1 R2 SAMPLE_BASENAME
  local r1=$1 r2=$2 sample=$3
  echo "[SPIKE‚ÄëIN] Aligning $sample to E.¬†coli genome‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
  "$STAR_PATH" --runThreadN "$NUM_THREADS" \
               --genomeDir  "$ECOLI_INDEX" \
               --readFilesIn "$r1" "$r2" \
               --readFilesCommand zcat \
               --outSAMtype BAM SortedByCoordinate \
               --outFileNamePrefix "$SPIKE_BAM_DIR/${sample}_ecoli_" \
               > "$LOG_DIR/STAR_${sample}_ecoli.log"  \
               2> "$LOG_DIR/STAR_${sample}_ecoli_error.log"

  local tmp="$SPIKE_BAM_DIR/${sample}_ecoli_Aligned.sortedByCoord.out.bam"
  if [[ -f "$tmp" ]]; then
    mv "$tmp" "$SPIKE_BAM_DIR/${sample}.ecoli.sorted.bam"
    samtools index "$SPIKE_BAM_DIR/${sample}.ecoli.sorted.bam"
  else
    echo "‚ùå Spike‚Äëin alignment failed for $sample ‚Äî BAM not produced." | tee -a "$LOG_DIR/pipeline.log"
    exit 1
  fi
}

bam_to_bedgraph () {
  local inbam=$1 outbg=$2
  # fragment-level coverage (-pc) ‚Üí BedGraph sorted by chrom,start
  bedtools genomecov -ibam "$inbam" -bg -pc | \
    sort -k1,1 -k2,2n > "$outbg"
}

# ------------------------------------------------------------------------------
# 4¬†¬†Derive filenames for downstream steps
# ------------------------------------------------------------------------------
TREATMENT_BASE=$(get_sample_basename "$TREATMENT_R1")
TREATMENT_TRIMMED_R1="$ALIGNMENT_DIR/${TREATMENT_BASE}_trimmed_R1.fq.gz"
TREATMENT_TRIMMED_R2="$ALIGNMENT_DIR/${TREATMENT_BASE}_trimmed_R2.fq.gz"

if [[ -n "$CONTROL_R1" ]]; then
  CONTROL_BASE=$(get_sample_basename "$CONTROL_R1")
  CONTROL_TRIMMED_R1="$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R1.fq.gz"
  CONTROL_TRIMMED_R2="$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R2.fq.gz"
fi

# ------------------------------------------------------------------------------
# 5¬†¬†Compute numeric genome size
# ------------------------------------------------------------------------------
GENOME_SIZE_HUMAN=2913022398; GENOME_SIZE_MOUSE=2652783500
GENOME_SIZE_DROSOPHILA=165000000; GENOME_SIZE_CELEGANS=1000000000
GENOME_SIZE_YEAST=12000000

case "$GENOME_SIZE_STRING" in
  hs) GENOME_SIZE=$GENOME_SIZE_HUMAN ;;
  mm) GENOME_SIZE=$GENOME_SIZE_MOUSE ;;
  dm) GENOME_SIZE=$GENOME_SIZE_DROSOPHILA ;;
  ce) GENOME_SIZE=$GENOME_SIZE_CELEGANS ;;
  sc) GENOME_SIZE=$GENOME_SIZE_YEAST ;;
  *)  if [[ "$CUSTOM_GENOME_SIZE" != "null" ]]; then
        GENOME_SIZE=$CUSTOM_GENOME_SIZE
      else
        echo "Error: Invalid genome size string $GENOME_SIZE_STRING" | tee -a "$LOG_DIR/pipeline.log"
        exit 1
      fi ;;
esac

echo "Using genome size $GENOME_SIZE for host genome: $GENOME_SIZE_STRING" | tee -a "$LOG_DIR/pipeline.log"

# ------------------------------------------------------------------------------
# 6¬†¬†FASTQC (raw reads)
# ------------------------------------------------------------------------------
FASTQ_FILES=("$TREATMENT_R1" "$TREATMENT_R2")
if [[ -n "$CONTROL_R1" ]]; then FASTQ_FILES+=("$CONTROL_R1" "$CONTROL_R2"); fi

echo "Running FastQC‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
for fq in "${FASTQ_FILES[@]}"; do
  $FASTQC_PATH --extract -o "$FASTQC_DIR" "$fq" >> "$LOG_DIR/pipeline.log" 2>&1
done

# ------------------------------------------------------------------------------
# 7  Adapter trimming (Trim Galore!)  ‚Äì  trim ALL declared FASTQ pairs
# ------------------------------------------------------------------------------
echo "[Trim Galore] starting‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
echo "DEBUG: FASTQ_FILES = ${FASTQ_FILES[*]}" | tee -a "$LOG_DIR/pipeline.log"

i=0
while [[ $i -lt ${#FASTQ_FILES[@]} ]]; do
  R1=${FASTQ_FILES[$i]}
  R2=${FASTQ_FILES[$((i+1))]}
  BASE=$(get_sample_basename "$R1")

  echo "  ‚Ü≥ trimming $BASE" | tee -a "$LOG_DIR/pipeline.log"
  trim_galore --paired --quality 20 --phred33 \
            --output_dir "$ALIGNMENT_DIR" "$R1" "$R2" \
            > "$LOG_DIR/trim_${BASE}.log" 2>&1

  VAL1=$(find "$ALIGNMENT_DIR" -name "*_val_1.fq.gz" | grep "$BASE" | head -n1)
  VAL2=$(find "$ALIGNMENT_DIR" -name "*_val_2.fq.gz" | grep "$BASE" | head -n1)

  if [[ -f "$VAL1" && -f "$VAL2" ]]; then
    mv "$VAL1" "$ALIGNMENT_DIR/${BASE}_trimmed_R1.fq.gz"
    mv "$VAL2" "$ALIGNMENT_DIR/${BASE}_trimmed_R2.fq.gz"
  else
    echo "‚ùå Trim Galore did not produce trimmed files for $BASE ‚Äî skipping." | tee -a "$LOG_DIR/pipeline.log"
  fi
  i=$((i+2))
done

# DEBUGGING
echo "DEBUG: FASTQ_FILES = ${FASTQ_FILES[*]}"
echo "DEBUG: R1=$R1  R2=$R2  BASE=$(get_sample_basename "$R1")" \
  | tee -a "$LOG_DIR/pipeline.log"

# ------------------------------------------------------------------------------
# 8 Include/exclude control sample logic (for downstream steps)
# ------------------------------------------------------------------------------
USE_CONTROL=0
if [[ -n "${CONTROL_BASE:-}" ]] && \
   [[ -f "$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R1.fq.gz" ]] && \
   [[ -f "$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R2.fq.gz" ]]; then
  USE_CONTROL=1
  CONTROL_TRIMMED_R1="$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R1.fq.gz"
  CONTROL_TRIMMED_R2="$ALIGNMENT_DIR/${CONTROL_BASE}_trimmed_R2.fq.gz"
else
  echo "‚ö†Ô∏è  No trimmed control FASTQs found ‚Äî proceeding without control." | tee -a "$LOG_DIR/pipeline.log"
fi

# Build sample list for the rest of the script
SAMPLES=("$TREATMENT_BASE")
[[ $USE_CONTROL -eq 1 ]] && SAMPLES+=("$CONTROL_BASE")

# ------------------------------------------------------------------------------
# 9  Spike-in alignment (E. coli)
# ------------------------------------------------------------------------------
echo "Aligning to the E. coli genome with STAR for subsequent spike-in scaling‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
run_spikein_align "$TREATMENT_TRIMMED_R1" "$TREATMENT_TRIMMED_R2" "$TREATMENT_BASE"

if [[ $USE_CONTROL -eq 1 ]]; then
  run_spikein_align "$CONTROL_TRIMMED_R1" "$CONTROL_TRIMMED_R2" "$CONTROL_BASE"
fi

# ------------------------------------------------------------------------------
# 10¬†¬†Host‚Äëgenome alignment (STAR)
# ------------------------------------------------------------------------------
echo "Aligning to the host genome with STAR‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
run_star "$REFERENCE_GENOME" \
         "$TREATMENT_TRIMMED_R1" "$TREATMENT_TRIMMED_R2" \
         "$ALIGNMENT_DIR/${TREATMENT_BASE}." "STAR_${TREATMENT_BASE}"

if [[ $USE_CONTROL -eq 1 ]]; then
  run_star "$REFERENCE_GENOME" \
           "$CONTROL_TRIMMED_R1" "$CONTROL_TRIMMED_R2" \
           "$ALIGNMENT_DIR/${CONTROL_BASE}." "STAR_${CONTROL_BASE}"
fi

# ------------------------------------------------------------------------------
# 11  Picard AddRG + MarkDuplicates          (only current-run BAMs)            
# ------------------------------------------------------------------------------
echo "[Picard] processing ${SAMPLES[*]}" | tee -a "$LOG_DIR/pipeline.log"

for samp in "${SAMPLES[@]}"; do
  in_bam="$ALIGNMENT_DIR/${samp}.Aligned.sortedByCoord.out.bam"
  [[ -s "$in_bam" ]] || { echo "‚ùå BAM not found: $in_bam" | tee -a "$LOG_DIR/pipeline.log"; exit 1; }

  java -jar "$PICARD_PATH" AddOrReplaceReadGroups \
       I="$in_bam" \
       O="$ALIGNMENT_DIR/${samp}.rg.bam" \
       RGID=1 RGLB=lib1 RGPL=ILLUMINA RGPU=unit1 RGSM="$samp" \
       VALIDATION_STRINGENCY=LENIENT

  java -jar "$PICARD_PATH" MarkDuplicates \
       I="$ALIGNMENT_DIR/${samp}.rg.bam" \
       O="$ALIGNMENT_DIR/${samp}.dedup.bam" \
       M="$LOG_DIR/${samp}.metrics.txt" \
       REMOVE_DUPLICATES=true \
       VALIDATION_STRINGENCY=LENIENT

  samtools index "$ALIGNMENT_DIR/${samp}.dedup.bam"
done

# ------------------------------------------------------------------------------
# 12¬†¬†Fragment‚Äëlength filtering
# ------------------------------------------------------------------------------
case "$FRAGMENT_SIZE_FILTER" in
  histones)              FRAG_CMD='{if ($9 >= 130 && $9 <= 300 || $1 ~ /^@/) print $0}' ;;
  transcription_factors) FRAG_CMD='{if ($9 < 130 || $1 ~ /^@/) print $0}' ;;
  *)                     FRAG_CMD='{if ($9 < 1000 || $1 ~ /^@/) print $0}' ;;
esac

echo "Filtering fragments by range $FRAGMENT_SIZE_FILTER‚Ä¶" | tee -a "$LOG_DIR/pipeline.log"
for bam in "$ALIGNMENT_DIR"/*.dedup.bam; do
  base=$(basename "$bam" .dedup.bam)
  samtools view -h "$bam" | awk "$FRAG_CMD" | samtools view -bS - > "$ALIGNMENT_DIR/${base}.dedup.filtered.bam"
done

# ------------------------------------------------------------------------------
# 13  Peak calling (SEACR)
# ------------------------------------------------------------------------------
echo "[SEACR] calling peaks" | tee -a "$LOG_DIR/pipeline.log"

# Make BedGraphs
TREAT_BG="$PEAK_DIR/${TREATMENT_BASE}.bedgraph"
bam_to_bedgraph "$ALIGNMENT_DIR/${TREATMENT_BASE}.dedup.filtered.bam" "$TREAT_BG"

if [[ $USE_CONTROL -eq 1 ]]; then
  CONTROL_BG="$PEAK_DIR/${CONTROL_BASE}.bedgraph"
  bam_to_bedgraph "$ALIGNMENT_DIR/${CONTROL_BASE}.dedup.filtered.bam" "$CONTROL_BG"
fi

# Run SEACR
if [[ $USE_CONTROL -eq 1 ]]; then
  # stringent (0.01) and relaxed (0.05) threshold examples
  bash "$SEACR" "$TREAT_BG" "$CONTROL_BG" non stringent "$PEAK_DIR/${TREATMENT_BASE}_seacr_1e-2.bed"
  bash "$SEACR" "$TREAT_BG" "$CONTROL_BG" non 0.05      "$PEAK_DIR/${TREATMENT_BASE}_seacr_0.05.bed"
else
  # no control ‚Üí use top X% of background
  bash "$SEACR" "$TREAT_BG" non stringent "$PEAK_DIR/${TREATMENT_BASE}_seacr_1e-2.bed"
  bash "$SEACR" "$TREAT_BG" non 0.05      "$PEAK_DIR/${TREATMENT_BASE}_seacr_0.05.bed"
fi

# Optionally convert BED to narrowPeak format
for bed in "$PEAK_DIR"/${TREATMENT_BASE}_seacr_*.bed; do
  awk 'BEGIN{OFS="\t"}{print $1,$2,$3,".",1000,"."}' "$bed" \
      > "${bed%.bed}.narrowPeak"
done


# ------------------------------------------------------------------------------
# 14  Spike-in scaling factors (per-run samples only)                         
# ------------------------------------------------------------------------------
echo "[Spike-in] calculating scale factors" | tee -a "$LOG_DIR/pipeline.log"

declare -A SCALE   # sample ‚Üí factor

count_reads() { samtools view -c -F 2304 "$1"; }

for samp in "${SAMPLES[@]}"; do
  host_bam="$ALIGNMENT_DIR/${samp}.dedup.filtered.bam"
  ecoli_bam="$SPIKE_BAM_DIR/${samp}.ecoli.sorted.bam"

  if [[ -f "$host_bam" && -f "$ecoli_bam" ]]; then
    host_reads=$(count_reads "$host_bam")
    spike_reads=$(count_reads "$ecoli_bam")

    if (( spike_reads > 0 )); then
      factor=$(awk -v h=$host_reads -v s=$spike_reads 'BEGIN{printf "%.6f", h/s}')
      echo "  ‚Ü≥ $samp : host=$host_reads  spike=$spike_reads  scale=$factor" \
           | tee -a "$LOG_DIR/pipeline.log"
      SCALE["$samp"]=$factor
    else
      echo "  ‚Ü≥ $samp : spike reads = 0 ‚Äî no scaling applied" \
           | tee -a "$LOG_DIR/pipeline.log"
    fi
  else
    echo "  ‚Ü≥ $samp : missing host or spike BAM ‚Äî skipped" \
         | tee -a "$LOG_DIR/pipeline.log"
  fi
done

# ------------------------------------------------------------------------------
# 15  BigWig generation (with optional scaling)                                
# ------------------------------------------------------------------------------
echo "[BigWig] generating coverage tracks" | tee -a "$LOG_DIR/pipeline.log"

for samp in "${SAMPLES[@]}"; do
  host_bam="$ALIGNMENT_DIR/${samp}.dedup.filtered.bam"
  [[ -f "$host_bam" ]] || { echo "‚ùå BAM missing for $samp ‚Äî skipping" | tee -a "$LOG_DIR/pipeline.log"; continue; }

  scale_opt=""
  if [[ -n "${SCALE[$samp]:-}" ]]; then
    echo "  ‚Ü≥ $samp : applying scaleFactor ${SCALE[$samp]}" | tee -a "$LOG_DIR/pipeline.log"
    # bedtools genomecov lacks a scale flag, so we multiply depth via awk
    scaled_bg="$BW_DIR/${samp}.scaled.bedgraph"
    bedtools genomecov -ibam "$host_bam" -bg -pc | \
      awk -v f="${SCALE[$samp]}" '{ $4=$4*f; print }' > "$scaled_bg"
    bedGraphToBigWig "$scaled_bg" "$CHROM_SIZE" "$BW_DIR/${samp}.bw"
  else
    echo "  ‚Ü≥ $samp : no scaleFactor (spike-in absent)" | tee -a "$LOG_DIR/pipeline.log"
    bedtools genomecov -ibam "$host_bam" -bg -pc > "$BW_DIR/${samp}.bedgraph"
    bedGraphToBigWig "$BW_DIR/${samp}.bedgraph" "$CHROM_SIZE" "$BW_DIR/${samp}.bw"
  fi
done

# ------------------------------------------------------------------------------
# 16¬†¬†Peak annotation
# ------------------------------------------------------------------------------
echo "[Peak annotation] intersecting peaks with gene features" | tee -a "$LOG_DIR/pipeline.log"

for samp in "${SAMPLES[@]}"; do
  peak_file="$PEAK_DIR/${TREATMENT_BASE}_seacr_0.05.narrowPeak"
  [[ -f "$peak_file" ]] || { echo "  ‚Ü≥ $samp : no narrowPeak file ‚Äî skipping" | tee -a "$LOG_DIR/pipeline.log"; continue; }

  full_out="$ANN_DIR/${samp}_peaks.annotated.bed"
  tsv_out="$ANN_DIR/${samp}_peaks.annotated.tsv"

  echo "  ‚Ü≥ annotating $samp" | tee -a "$LOG_DIR/pipeline.log"

  # full BED12 style intersect (peak + gene feature columns)
  bedtools intersect -a "$peak_file" -b "$ANNOTATION_GENES" -wa -wb > "$full_out"

  # concise TSV: peak coords + gene name + strand
  awk 'BEGIN{OFS="\t"} {print $1,$2,$3,$10,$11,$12}' "$full_out" > "$tsv_out"
done

echo "üéâ  CUT&RUN pipeline complete!  Results are in: $OUTPUT_DIR" | tee -a "$LOG_DIR/pipeline.log"

